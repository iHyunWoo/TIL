## 2025-02-06

## 새로 배운 내용
### 동시성과 병럴성
##### - 동시성
- 하나의 CPU에서 여러 작업(프로세스 또는 스레드)이 동시에 실행되는 것처럼 보이게 하는 개념
- CPU가 대기 상태로 머무르지 않고 연속적으로 작업을 처리하여 효율적인 자원 활용과 사용자 경험 개선
- 특징
    - 작업 간 전환: 여러 작업을 빠르게 전환하며 실행(실제 병렬 실행 X)
    - 자원 공유: 여러 작업이 동일한 CPU와 메모리를 공유하며 동작
    - 스케쥴링: OS가 스케쥴링을 통해 작업 실행 순서를 조정하여 멀티태스킹 구현
    - I/O중심 작업(파일 입출력, 네트워크 처리 등)에서 효과적(입력 대기 시 CPU도 대기하기 때문
##### - 병렬성
- 여러 CPU 코어 또는 다중 프로세서를 활용하여 여러 작업을 물리적으로 동시에 실행하는 기술
- 동시성과 달리 작업이 실제로 동시에 실행되며, 하드웨어 지원이 필수
- 특징
    - 작업의 독립성: 각 작업이 서로 간섭 없이 물리적으로 독립적으로 실행
    - 계산 중심: 대규모 데이터 처리, 연산 중심 작업, 병렬 알고리즘에 최적화
    - 코어 수가 많을수록 더 많은 작업을 동시에 처리 가능
##### - 동시성과 병렬성의 차이
- 동시성
	- 하나의 CPU에서 스케쥴링을 통해 작업을 전환하며 실행
	- I/O 작업에 효과적
	- 하드웨어와 무관하게 구현 가능

- 병렬성
	- 여러 CPU에서 작업을 물리적으로 분리하여 다중 코어에서 동시에 실행
	- 계산 작업 중심 프로그램(머신러닝 등)
	- 다중 코어 및 병렬 처리 지원 하드웨어 필요

### 스케쥴러
- 시스템 자원을 적절히 분배하기 위해 프로세스나 스레드의 실행 순서를 결정하는 역할
- 우선순위에 따라 어떤 작업을 실행할지 결정
- 시스템 자원을 여러 작업이 공평하게 사용할 수 있도록 분배
- 컨텍스트 스위칭 관리: 실행중인 작업의 상태를 저장하고 새로운 작업의 상태를 불러와 전환하는 것

### 스케쥴링 알고리즘
- 비선점형 스케쥴링
    - 이미 할당된 CPU를 다른 프로세스가 강제로 빼앗아 사용할 수 없음
    - 컨텍스트 스위칭 오버헤드가 낮지만 응답속도가 느림
    - FCFS(First Come First Served)
        - 먼저 도착한 프로세스부터 실행
        - 짧은 작업이 긴 작업을 기다리는 경우 발생 가능 → 콘보이 현상
        - 프로세스 응답 시간 예측 용이, 일괄 처리 방식(배치)에 적합
    - SJF(Shortest Job First)
        - 실행 시간이 가장 짧은 프로세스를 먼저 실행
        - 짧은 프로세스부터 실행하기 때문에 콘보이 현상은 부분 해결
        - 실행시간이 긴 프로세스가 영원히 CPU를 할당 받을 수 없음 → 기아 상태
- 선점형 스케쥴링
    - 현재 실행 중인 프로세스보다 우선순위가 더 높은 프로세스가 도착하면 cpu를 뺏김
    - 응답속도는 빠르지만 컨텍스트 스위칭 오버헤드 증가
    - SRTF(Shortest Remaining Time First)
        - 남은 실행 시간(총 시간-실행했던 시간)이 가장 짧은 프로세스를 우선 실행
        - SJF와 마찬자기로 기아 상태 발생 가능
    - RR(Round Robin)
        - 모든 프로세스에게 고정된 시간(Time Quantum) 동안 CPU를 할당 후 다음 프로세스로 교체
        - 할당 받은 시간이 지나면 Ready 상태로 돌아가 준비 큐의 끝으로 들어감
        - 모든 프로세스가 공정하게 CPU를 할당받을 수 있음
        - 응답시간이 빠름. n개의 프로세스가 할당시간이 q라면 어떤 프로세스도 (n-1)*q 이상 기다리지 않음
        - Time Quantum이 너무 커지면 FCFS와 같아짐. 너무 작아지면 컨텍스트 스위치 오버헤드 증가

### 컨텍스트 스위칭
- CPU가 실행중인 프로세스 또는 스레드를 변경하면서 이전 상태를 저장하고 새로운 상태를 로드하는 과정
- 스레드풀
    - 미리 생성된 스레드 그룹을 재사용하는 방식
    - 스레드 생성 및 삭제에 따른 오버헤드를 줄일 수 있어 시스템 자원을 효율적으로 관리
    - 하지만 스레드를 할당 받지 못한 태스트들은 빈 스레드가 생기기 전까지 스레드를 할당받지 못함
- 암달의 법칙
    - 컨텍스트 스위칭이 많으면 병렬화 효과가 떨어짐
    - 스레드를 너무 많이 만들면 오히려 오버헤드가 증가하여 성능이 저하될 수 있음.
    - 수식: S(n) = 1 / [(1 - P) + (P / n)]
        - S(n) = n개의 프로세서를 사용할 때 전체 시스템의 성능 향상 비율.
        - P = 병렬화 가능한 작업의 비율
        - n = 사용되는 프로세서의 수
        - (1 - P) = 병렬처리가 불가능한 부분
        - ex) 병렬화 비율이 50%라 가정한다면, S(n) = 1/(0.5+ (0.5/n))
            - 프로세스가 2개라면 S(n) = 4/3 = 133.3% 성능 향상
            - 프로세서가 4개라면 S(n) = 8/5 = 160% 성능 향상
            - 프로세스가 8개라면 S(n) = 16/9 = 177.7% 성능 향상
            - 프로세서가 16개라면 S(n) = 32/17 = 188.2% 성능 향상
            - → 프로세서를 최대한 사용하는 것이 효율적인 방법이 아님. 적절한 개수를 찾기
- c10k 문제
    - Concurrent 10K users: 동시 사용자 1만명이 접속하는 서버를 구현하는 문제
    - 1만명의 유저가 접속하는 채팅 서비스를 가정.
        - 그러면 1만개의 스레드를 생성?
        - 컨텍스트 스위칭이 엄청 발생. 각 스레드가 자신의 실행 시간을 할당 받기 위해 계속 polling 경쟁
        - 대안) event-driven 방식
            - 이벤트(요청)와 io처리를 분리
            - 이벤트루프는 싱글스레드
            - io처리는 비동기적으로 실행

### [[AJAX. 그리고 Fetch와 Axios]]
- [AJAX. 그리고 Fetch와 Axios](https://github.com/iHyunWoo/TIL/blob/main/Document/JS%20%26%20TS/AJAX.%20%EA%B7%B8%EB%A6%AC%EA%B3%A0%20Fetch%EC%99%80%20Axios.md)

## 오늘의 도전 과제와 해결 방법
- TIL을 옵시디언으로 편하게 보기위한 방법들을 열심히 고안해봤다.   
로컬의 파일 링크와 깃헙에 올라가있는 외부 링크를 둘 다 넣어야 하는데, 더 깔끔한 방법을 찾느라 신경을 썼다.


## 오늘의 회고
- TIL 폴더 구조를 변경해봤다.   
기존처럼 기록하면 단순히 TIL을 적는 용도지 내가 적은 문서들을 다시 확인하기엔 최적화 되어있진 않기에..